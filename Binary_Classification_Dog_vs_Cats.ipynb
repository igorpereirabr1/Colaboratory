{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary-Classification-Dog-vs-Cats.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igorpereirabr1/Colaboratory/blob/master/Binary_Classification_Dog_vs_Cats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1m_6KlxMQ1Y",
        "colab_type": "text"
      },
      "source": [
        "# 00 - Objective\n",
        "\n",
        "Implement a CNN with Keras and Tensorflow to predict classes of images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOjMXyQpB-s9",
        "colab_type": "text"
      },
      "source": [
        "# 01- Mount Directory and Define project Path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmkA5RCnBrVv",
        "colab_type": "code",
        "outputId": "8f0570f0-c035-4157-da93-f8e87e468f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "project_path = \"/content/gdrive/My Drive/01-DataScience/01-Deep Learning/01-Keras/00-CNN\"\n",
        "\n",
        "dataset_path = \"/content/gdrive/My Drive/01-DataScience/01-Deep Learning/00-Datasets\"\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM4Myelbqng_",
        "colab_type": "text"
      },
      "source": [
        "# 02 - Download the Dataset and Unzip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j-Me2KscBT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set current path to download files\n",
        "\n",
        "os.chdir(dataset_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UymlT-04cBEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download the Dataset\n",
        "##!wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmMQ4cAcmXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unzip the dataset\n",
        "!unzip kagglecatsanddogs_3367a.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RSukOTuoJaL",
        "colab_type": "code",
        "outputId": "7a3d2830-e929-44e4-d6a2-a8e9d191b622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "#Check current files\n",
        "!ls -la"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 16\n",
            "drwxr-xr-x 1 root root 4096 May 13 16:47 .\n",
            "drwxr-xr-x 1 root root 4096 May 16 10:25 ..\n",
            "drwxr-xr-x 1 root root 4096 May 13 16:48 .config\n",
            "drwxr-xr-x 1 root root 4096 May 13 16:48 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIPTMqYkwVPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Remove zip file \n",
        "!rm kagglecatsanddogs_3367a.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvrbU2bIdHSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZA-AfBE6B4zY",
        "colab_type": "text"
      },
      "source": [
        "# 03 -Importing Libraries and Splitting the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enwye1W6CKpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D,Conv2D,Dropout\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras import regularizers\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import History \n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g39J0L0FssEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "#Step 1  - Convulution\n",
        "classifier.add(Conv2D(32,(3,3),input_shape= (64, 64, 3),activation='relu'))\n",
        "#classifier.add(Convolution2D(32,3,3,input_shape= (64, 64, 3),activation='relu'))\n",
        "\n",
        "#Step 2 - Polling\n",
        "classifier.add(MaxPooling2D(pool_size=(3,3)))\n",
        "\n",
        "#Dropout to prevent overfitting\n",
        "#classifier.add(Dropout(0.5))\n",
        "\n",
        "################################\n",
        "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "################################\n",
        "\n",
        "\n",
        "#Step 3 - Flatten\n",
        "classifier.add(Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-16pWVhotnnb",
        "colab_type": "text"
      },
      "source": [
        "# 4 — Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj2sAAAjssdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Step 4 - Full Connection\n",
        "#classifier.add(Dense(output_dim=128,activation='relu'))\n",
        "classifier.add(Dense(activation=\"relu\", units=128))\n",
        "\n",
        "#Dropout to prevent overfitting\n",
        "classifier.add(Dropout(0.5))\n",
        "\n",
        "classifier.add(Dense(activation=\"relu\", units=64))\n",
        "\n",
        "#classifier.add(Dense(output_dim=1,activation='sigmoid'))\n",
        "classifier.add(Dense(units=1,activation='sigmoid'))\n",
        "\n",
        "\n",
        "\n",
        "#Step 5 - Compile the CNN\n",
        "\n",
        "classifier.compile(optimizer = \"adam\", loss='binary_crossentropy', metrics = ['accuracy'],)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT3SJBjg9Ihm",
        "colab_type": "text"
      },
      "source": [
        "# 5 - Split the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klLnqwtqoosI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6e6970e3-339d-4c30-cbf2-5fbe1dbd241e"
      },
      "source": [
        "#remove corrupted image files\n",
        "\n",
        "!rm '/content/gdrive/My Drive/01-DataScience/01-Deep Learning/00-Datasets/PetImages/Dog/11703.jpg'\n",
        "!rm '/content/gdrive/My Drive/01-DataScience/01-Deep Learning/00-Datasets/PetImages/Cat/666.jpg'\n",
        "!rm '/content/gdrive/My Drive/01-DataScience/01-Deep Learning/00-Datasets/PetImages/Dog/11702.jpg'"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/gdrive/My Drive/01-DataScience/01-Deep Learning/00-Datasets/PetImages/Dog/11703.jpg': No such file or directory\n",
            "rm: cannot remove '/content/gdrive/My Drive/01-DataScience/01-Deep Learning/00-Datasets/PetImages/Cat/666.jpg': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlWdDQU2uRyJ",
        "colab_type": "code",
        "outputId": "16a33d35-db3e-43f7-9115-0d723fc04fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "\n",
        "\n",
        "#set the new dataset path\n",
        "dataset_path = os.path.join(dataset_path,'PetImages')\n",
        "\n",
        "#For this case, we don't need use Data Augmentation, cause we have a big dataset\n",
        "datagen = ImageDataGenerator(rescale=1./255\n",
        "                                   ,validation_split=0.33\n",
        "        ,shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "\n",
        "\n",
        "training_set = datagen.flow_from_directory(\n",
        "        directory=dataset_path,\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        #classes=['Dog','Cat'],\n",
        "        subset = \"training\",\n",
        "        #save_to_dir = '/content/gdrive/My Drive/Colab Notebooks/01ComputerVision/01OpenCV/02_CNN_Keras_Tensorflow/03_CNN_Keras_Tensorflow_FaceDetection/train_set',\n",
        "        class_mode='binary')\n",
        "\n",
        "test_set = datagen.flow_from_directory(\n",
        "       directory=dataset_path,\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        #classes=['Dog','Cat'],\n",
        "        subset = \"validation\",\n",
        "        #save_to_dir = '/content/gdrive/My Drive/Colab Notebooks/01ComputerVision/01OpenCV/02_CNN_Keras_Tensorflow/03_CNN_Keras_Tensorflow_FaceDetection/validation_set',\n",
        "        class_mode='binary')\n",
        "\n",
        "STEP_SIZE_TRAIN=training_set.n//training_set.batch_size\n",
        "STEP_SIZE_VALID=test_set.n//test_set.batch_size"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16749 images belonging to 2 classes.\n",
            "Found 8248 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I94m2Zmx7s_e",
        "colab_type": "text"
      },
      "source": [
        "# 6 - Training CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8uibLrwuR43",
        "colab_type": "code",
        "outputId": "87e75b18-8978-4109-ae73-22aa327949db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "history = History()\n",
        "epochs = 100\n",
        "\n",
        "classifier.fit_generator(training_set,steps_per_epoch=STEP_SIZE_TRAIN,epochs=epochs,validation_data=test_set,validation_steps=STEP_SIZE_VALID,callbacks=[history])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r523/523 [==============================] - 266s 509ms/step - loss: 0.4760 - acc: 0.7767 - val_loss: 0.4611 - val_acc: 0.7801\n",
            "Epoch 6/100\n",
            "456/523 [=========================>....] - ETA: 25s - loss: 0.4563 - acc: 0.7863"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWnsTiWuuR-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save the Model and Weights\n",
        "import json \n",
        "# serialize model to JSON\n",
        "model_json = classifier.to_json()\n",
        "with open(os.path.join(project_path,\"Binary-Classification-Dog-vs-Cats - model.json\"), \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "classifier.save_weights(os.path.join(project_path,\"Binary-Classification-Dog-vs-Cats - weights.h5\"))\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLIjf8Anp5X0",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate out model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYxEhxu8EW3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
        "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
        "ax1.set_xticks(np.arange(1, epochs, 1))\n",
        "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
        "\n",
        "ax2.plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
        "ax2.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
        "ax2.set_xticks(np.arange(1, epochs, 1))\n",
        "\n",
        "legend = plt.legend(loc='best', shadow=True)\n",
        "plt.label=True\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBUtJ2HH3wB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255\n",
        "  ,validation_split=0.5\n",
        "  ,shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "\n",
        "validation_set = validation_datagen.flow_from_directory(\n",
        "       directory=dataset_path,\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        subset = \"validation\",\n",
        "        class_mode='binary')\n",
        "\n",
        "STEP_SIZE_VALID=validation_set.n//validation_set.batch_size\n",
        "\n",
        "\n",
        "#predictions = classifier.predict_generator(validation_set, steps=STEP_SIZE_VALID)\n",
        "\n",
        "#loss, acc = classifier.evaluate_generator(validation_set, steps=STEP_SIZE_VALID, verbose=0)\n",
        "\n",
        "#print(\" The Accuracy for this model is :\"+str(acc), \" and the Loss is it \"+str(loss))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiWYn0zkCvS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f5d5439b-e4fe-4d5e-ce42-f699d3637814"
      },
      "source": [
        "dataset_path"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/01-DataScience/01-Deep Learning/00-Datasets'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdZzioVsFN_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classe_map = validation_set.class_indices\n",
        "\n",
        "threshold = 0.5\n",
        "\n",
        "df = pd.DataFrame()\n",
        "\n",
        "\n",
        "df['labels'] = validation_set.labels\n",
        "df['filepaths'] = validation_set.filepaths\n",
        "df['filename'] = validation_set.filenames\n",
        "df['name'] = [str(k).split('/')[0] for k in validation_set.filenames]\n",
        "\n",
        "df['probability'] = predictions\n",
        "df['category'] = np.where(df['probability'] > threshold, 1,0)\n",
        "df['category_name'] = df['category'].apply(lambda x: list(classe_map.keys())[list(classe_map.values()).index(x)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZhnoAANHLpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SIZE = validation_set.image_shape[:-1]\n",
        "\n",
        "np.random.np.random.randint\n",
        "\n",
        "ix = np.random.np.random.randint(len(df)-18)\n",
        "\n",
        "sample_test = df[ix:ix+18]\n",
        "sample_test.head()\n",
        "plt.figure(figsize=(12, 24))\n",
        "index =0\n",
        "for x, row in sample_test.iterrows():\n",
        "    filename = row['filename']\n",
        "    category = row['category_name']\n",
        "    probability = row['probability']\n",
        "    file_path = row['filepaths']\n",
        "    img = load_img(file_path, target_size=IMAGE_SIZE)\n",
        "    plt.subplot(6, 3, index+1)\n",
        "    index +=1\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' '(' + \"{}\".format(round(probability, 2)) + ')')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctUWqkaJIOt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}